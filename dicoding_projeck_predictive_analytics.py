# -*- coding: utf-8 -*-
"""Dicoding Projeck Predictive Analytics

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IJcQcQ691gcq-BsTR42pIQnOKbrOJ4z6

**DATA DIRI**

**NAMA : MUHAMMAD ISMAIL**

**DOMISILI : SURABAYA, JAWA TIMUR**

**PREDICTIVE ANALYTICS PROJECT**

#Import Libraries dan Dataset
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

url = "https://raw.githubusercontent.com/tidyverse/ggplot2/master/data-raw/tx-housing.csv"
texasHouses = pd.read_csv(url)
texasHouses

texasHouses.info()

texasHouses.shape

texasHouses.isnull().sum()

"""#EDA"""

texasHouses.describe()

"""##**WORKING WITH MISSING VALUES**"""

# texasHouses['listings'] = texasHouses['listings'].fillna(texasHouses['listings'].mean())
# texasHouses['volume'] = texasHouses['volume'].fillna(texasHouses['volume'].mean())
# texasHouses['median'] = texasHouses['median'].fillna(texasHouses['median'].mean())
# texasHouses['inventory'] = texasHouses['inventory'].fillna(texasHouses['inventory'].mean())
# texasHouses['sales'] = texasHouses['sales'].fillna(texasHouses['sales'].median())
texasHouses = texasHouses.loc[(texasHouses[['listings', 'inventory']]!= 0).all(axis=1)]
texasHouses.dropna(subset = ["sales","volume","median","listings","inventory"], inplace=True)
texasHouses.drop(['date'], axis=1, inplace=True)
texasHouses.describe()

texasHouses.isnull().sum()

texasHouses.shape

Q1 = texasHouses.quantile(.25)
Q3 = texasHouses.quantile(.75)

IQR = Q3 - Q1
texasHouses = texasHouses[~((texasHouses < (Q1-1.5*IQR))|(texasHouses > (Q3+1.5*IQR))).any(axis=1)]
texasHouses

"""**MENGUBAH KOLOM year dan month MENJADI CATEGORICAL FEATURES**"""

texasHouses[['year','month']] = texasHouses[['year','month']].astype(str)
texasHouses

"""##**MENAMBAHKAN BARIS AGAR MEMILIKI DATA LEBIH BANYAK**"""

df2 = texasHouses[['volume','median','listings','inventory']].add(220)
df3 = texasHouses[['volume','median','listings','inventory']].add(120)
df4 = texasHouses[['volume','median','listings','inventory']].add(167)
df5 = texasHouses[['volume','median','listings','inventory']].add(284)
df6 = texasHouses[['volume','median','listings','inventory']].add(539)
df7 = texasHouses[['volume','median','listings','inventory']].add(736)
df8 = texasHouses[['volume','median','listings','inventory']].add(657)
df9 = texasHouses[['volume','median','listings','inventory']].add(828)
df2['sales'] = texasHouses[['sales']].add(1)
df3['sales'] = texasHouses[['sales']].add(2)
df4['sales'] = texasHouses[['sales']].add(2)
df5['sales'] = texasHouses[['sales']].add(3)
df6['sales'] = texasHouses[['sales']].add(3)
df7['sales'] = texasHouses[['sales']].add(1)
df8['sales'] = texasHouses[['sales']].add(5)
df9['sales'] = texasHouses[['sales']].add(2)
df9[['city','year','month']] = texasHouses[['city','year','month']]
df8[['city','year','month']] = texasHouses[['city','year','month']]
df7[['city','year','month']] = texasHouses[['city','year','month']]
df6[['city','year','month']] = texasHouses[['city','year','month']]
df5[['city','year','month']] = texasHouses[['city','year','month']]
df4[['city','year','month']] = texasHouses[['city','year','month']]
df3[['city','year','month']] = texasHouses[['city','year','month']]
df2[['city','year','month']] = texasHouses[['city','year','month']]
texasHouses = pd.concat([texasHouses, df2, df3, df4, df5, df6, df7, df8, df9], ignore_index = True, axis = 0)
texasHouses

texasHouses.info()

"""**MELIHAT TOTAL JUMLAH RUMAH YANG DIBELI DI KOTA DAERAH TEXAS**"""

numerical_features = ['sales', 'volume', 'median', 'listings', 'inventory']
categorical_features = ['city', 'year', 'month']

feature = categorical_features[0]#kolom city
count = texasHouses[feature].value_counts() # hitung banyak city
plt.figure(figsize =(20,6))
count.plot(kind='bar', title=feature);

"""**BANYAK PENJUALAN RUMAH DI KOTA DAERAH TEXAS DARI TAHUN 2003 - 2015**"""

feature = categorical_features[1]
count = texasHouses[feature].value_counts()
plt.figure(figsize =(20,6))
count.plot(kind='bar', title=feature);

texasHouses.hist(bins=50, figsize=(20,15))
plt.show()

plt.figure(figsize =(50,50))
sns.catplot(x="sales", y="city", dodge = False, kind="bar", height = 8, aspect = 2, data=texasHouses, palette="Set3")
plt.title("Rata-rata 'sales' Relatif terhadap Kota-kota di texas")

# mengamati hubungan antar fitur numerik dengan fungsi pairplot()
sns.pairplot(texasHouses, diag_kind = 'kde')

plt.figure(figsize=(20, 8))
correlation_matrix = texasHouses.corr().round(2)
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""**MENGDROP KOLOM INVENTORY KARENA MEMILIKI KORELASI RENDAH DENGAN FITUR NUMERIK**"""

texasHouses.drop(['inventory'], inplace=True, axis=1)
texasHouses.head()

texasHouses.info()



"""#ENCODING"""

from sklearn.preprocessing import  OneHotEncoder
texasHouses = pd.concat([texasHouses, pd.get_dummies(texasHouses['city'], prefix='city', drop_first=True)],axis=1)
texasHouses = pd.concat([texasHouses, pd.get_dummies(texasHouses['year'], prefix='year', drop_first=True)],axis=1)
texasHouses = pd.concat([texasHouses, pd.get_dummies(texasHouses['month'], prefix='month', drop_first=True)],axis=1)
texasHouses.drop(['city','year','month'], axis=1, inplace=True)
texasHouses.head()

from sklearn.model_selection import train_test_split

X = texasHouses[["volume", "median", "listings"]]
y= texasHouses["sales"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .1, random_state = 27)

X

y

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""#EVALUATION"""

# Siapkan daraframe untuk analisis model
models = pd.DataFrame(index=['train_mse', 'test_mse'], 
                      columns=['KNN', 'RandomForest', 'BoostingADA', 'BoostingGR'])

y_train.isnull().sum()

"""##**MODEL DEV DENGAN KNN**"""

from sklearn.neighbors import KNeighborsRegressor
 
knn = KNeighborsRegressor(n_neighbors=20)
knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_train)

y_pred_knn

"""##**MODEL DEV DENGAN RANDOM FOREST**"""

# Impor library yang dibutuhkan
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import RandomForestRegressor
 
# buat model prediksi
RF = RandomForestRegressor(n_estimators=50, max_depth= 19, random_state= 45, n_jobs=-1)
RF.fit(X_train, y_train)
y_pred_RF= RF.predict(X_train)
models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

y_pred_RF

"""##**MODEL DEV DENGAN ADAPTIVE BOOSTING**"""

from sklearn.ensemble import AdaBoostRegressor
 
boostingADA = AdaBoostRegressor(n_estimators=35, learning_rate=0.05, random_state= 35)                             
boostingADA.fit(X_train, y_train)
y_pred_AB= boostingADA.predict(X_train)
models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boostingADA.predict(X_train), y_true=y_train)

y_pred_AB

"""##**MODEL DEV DENGAN GRADIENT BOOSTING**"""

from sklearn.ensemble import GradientBoostingRegressor

boostingGR = GradientBoostingRegressor(n_estimators=35, learning_rate=0.05, random_state= 35)                             
boostingGR.fit(X_train, y_train)
y_pred_GB= boostingGR.predict(X_train)
models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boostingGR.predict(X_train), y_true=y_train)

y_pred_GB

mse = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','BoostingADA', 'BoostingGR'])
model_dict = {'KNN': knn, 'RF': RF, 'BoostingADA': boostingADA, 'BoostingGR': boostingGR}
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3 
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3
 
mse

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

prediksi = X_test.iloc[:].copy()
pred_dict = {'y_true':y_test[:]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)
 
pred_dict = pd.DataFrame(pred_dict)
pred_dict